{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ6IOAZhPfq_"
      },
      "source": [
        "## Notebook for Epithelial labels transfer and datasets integration \n",
        "\n",
        "- **Developed by**: Anna Maguza\n",
        "- **Institute of Computational Biology - Computational Health Centre - Helmholtz Munich**\n",
        "- 15th May 2023"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROXh768hPkfT"
      },
      "source": [
        "### Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzu4WytePpBb",
        "outputId": "e93cba57-5021-4298-c1cf-a0c308c1142b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scarches\n",
            "  Downloading scArches-0.5.8-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.6/120.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scvi-tools\n",
            "  Downloading scvi_tools-0.20.3-py3-none-any.whl (330 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.3/330.3 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scib\n",
            "  Downloading scib-1.1.3-1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scib_metrics\n",
            "  Downloading scib_metrics-0.3.3-py3-none-any.whl (35 kB)\n",
            "Collecting scvi_colab\n",
            "  Downloading scvi_colab-0.12.0-py3-none-any.whl (4.2 kB)\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scanpy>=1.6.0 (from scarches)\n",
            "  Downloading scanpy-1.9.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting anndata>=0.7.4 (from scarches)\n",
            "  Downloading anndata-0.9.1-py3-none-any.whl (102 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scHPL>=1.0.0 (from scarches)\n",
            "  Downloading scHPL-1.0.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from scarches) (3.8.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from scarches) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.19.2 in /usr/local/lib/python3.10/dist-packages (from scarches) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from scarches) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from scarches) (1.2.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from scarches) (3.7.1)\n",
            "Requirement already satisfied: pandas>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from scarches) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.56.0 in /usr/local/lib/python3.10/dist-packages (from scarches) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from scarches) (2.27.1)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from scarches) (4.6.6)\n",
            "Collecting leidenalg (from scarches)\n",
            "  Downloading leidenalg-0.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting muon (from scarches)\n",
            "  Downloading muon-0.1.3-py3-none-any.whl (291 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.5/291.5 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chex in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.1.7)\n",
            "Collecting docrep>=0.3.2 (from scvi-tools)\n",
            "  Downloading docrep-0.3.2.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.6.9)\n",
            "Requirement already satisfied: jax>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.4.8)\n",
            "Requirement already satisfied: jaxlib>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.4.7+cuda11.cudnn86)\n",
            "Collecting ml-collections>=0.1.1 (from scvi-tools)\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mudata>=0.1.2 (from scvi-tools)\n",
            "  Downloading mudata-0.2.2-py3-none-any.whl (23 kB)\n",
            "Collecting numpyro (from scvi-tools)\n",
            "  Downloading numpyro-0.11.0-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.2/300.2 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: openpyxl>=3.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (3.0.10)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.1.5)\n",
            "Collecting pyro-ppl>=1.6.0 (from scvi-tools)\n",
            "  Downloading pyro_ppl-1.8.4-py3-none-any.whl (730 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.7/730.7 kB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-lightning<1.10.0,>=1.9.0 (from scvi-tools)\n",
            "  Downloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (13.3.4)\n",
            "Collecting torchmetrics>=0.11.0 (from scvi-tools)\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from scib) (0.12.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from scib) (0.56.4)\n",
            "Collecting scikit-misc (from scib)\n",
            "  Downloading scikit_misc-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting umap-learn (from scib)\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (from scib) (1.4.2)\n",
            "Collecting igraph>=0.10 (from scib)\n",
            "  Downloading igraph-0.10.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: llvmlite in /usr/local/lib/python3.10/dist-packages (from scib) (0.39.1)\n",
            "Collecting deprecated (from scib)\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting plottable (from scib_metrics)\n",
            "  Downloading plottable-0.1.5-py3-none-any.whl (24 kB)\n",
            "Collecting pynndescent (from scib_metrics)\n",
            "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from anndata>=0.7.4->scarches) (8.3.1)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from anndata>=0.7.4->scarches) (23.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from docrep>=0.3.2->scvi-tools) (1.16.0)\n",
            "Collecting texttable>=1.6.2 (from igraph>=0.10->scib)\n",
            "  Downloading texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.4->scvi-tools) (0.1.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.4->scvi-tools) (3.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.1->scarches) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.1->scarches) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.1->scarches) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.1->scarches) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.1->scarches) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.1->scarches) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.1->scarches) (2.8.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from ml-collections>=0.1.1->scvi-tools) (1.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from ml-collections>=0.1.1->scvi-tools) (6.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from ml-collections>=0.1.1->scvi-tools) (0.6.0.post1)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl>=3.0->scvi-tools) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.2->scarches) (2022.7.1)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.6.0->scvi-tools)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<1.10.0,>=1.9.0->scvi-tools) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<1.10.0,>=1.9.0->scvi-tools) (4.5.0)\n",
            "Collecting lightning-utilities>=0.6.0.post0 (from pytorch-lightning<1.10.0,>=1.9.0->scvi-tools)\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->scvi-tools) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->scvi-tools) (2.14.0)\n",
            "Requirement already satisfied: statsmodels>=0.10.0rc2 in /usr/local/lib/python3.10/dist-packages (from scanpy>=1.6.0->scarches) (0.13.5)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from scanpy>=1.6.0->scarches) (0.5.3)\n",
            "Requirement already satisfied: networkx>=2.3 in /usr/local/lib/python3.10/dist-packages (from scanpy>=1.6.0->scarches) (3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scanpy>=1.6.0->scarches) (1.2.0)\n",
            "Collecting session-info (from scanpy>=1.6.0->scarches)\n",
            "  Downloading session_info-1.0.0.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->scib) (67.7.2)\n",
            "Collecting newick~=1.0.0 (from scHPL>=1.0.0->scarches)\n",
            "  Downloading newick-1.0.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.2->scarches) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scarches) (3.12.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scarches) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scarches) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->scarches) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->scarches) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->scarches) (16.0.5)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex->scvi-tools) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex->scvi-tools) (0.12.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->scib) (1.14.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->scvi-tools) (1.0.5)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->scvi-tools) (0.2.1)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->scvi-tools) (0.1.36)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->scarches) (4.11.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from muon->scarches) (3.20.3)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from numpyro->scvi-tools) (0.6.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->scarches) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->scarches) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->scarches) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->scarches) (3.4)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.9.0->scvi-tools)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=12.0.0->scvi-tools) (0.1.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->scarches) (2.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->scarches) (2.1.2)\n",
            "Requirement already satisfied: cached_property in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->scvi-tools) (1.5.2)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->scvi-tools) (5.12.0)\n",
            "Requirement already satisfied: etils in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->scvi-tools) (1.2.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->scvi-tools) (1.5.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests->scarches) (1.7.1)\n",
            "Collecting stdlib_list (from session-info->scanpy>=1.6.0->scarches)\n",
            "  Downloading stdlib_list-0.8.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->scarches) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.9.0->scvi-tools) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.9.0->scvi-tools)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.9.0->scvi-tools)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.9.0->scvi-tools)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.9.0->scvi-tools)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<1.10.0,>=1.9.0->scvi-tools)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Building wheels for collected packages: docrep, ml-collections, umap-learn, pynndescent, session-info\n",
            "  Building wheel for docrep (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docrep: filename=docrep-0.3.2-py3-none-any.whl size=19877 sha256=c0470a51e561cfbc5376bfade352c0c4c98c3a2cd2141267b2adc12e45056861\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/64/48/03c38d8d906159eaa210b3c548fdb590eb3e2a4a5745ae2172\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94506 sha256=680cd4defccecd9092161d01603cdb46b1a625835c65c15ef1c8eb7231fd7d05\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82816 sha256=5edac316a71a677ac7106196a060e69cfaa0dfec0b248f3a3cbd486a903923da\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/e8/c6/a37ea663620bd5200ea1ba0907ab3c217042c1d035ef606acc\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55622 sha256=df30e5a37b7667b619e1b58ac2d6f2f8d7bc8d409770c0f079070a17ad07d33e\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/38/5d/f60a40a66a9512b7e5e83517ebc2d1b42d857be97d135f1096\n",
            "  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8026 sha256=c88bfd8bd2a1f61a0528cf9dc82e2dd36342e833a6b33dee5e4174fa23b32022\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/aa/b9/eb5d4031476ec10802795b97ccf937b9bd998d68a9b268765a\n",
            "Successfully built docrep ml-collections umap-learn pynndescent session-info\n",
            "Installing collected packages: texttable, stdlib_list, pyro-api, newick, faiss-gpu, session-info, scikit-misc, multidict, ml-collections, lightning-utilities, igraph, frozenlist, docrep, deprecated, async-timeout, yarl, leidenalg, aiosignal, scvi_colab, pynndescent, plottable, numpyro, anndata, aiohttp, umap-learn, scHPL, mudata, scanpy, scib_metrics, scib, muon, torchmetrics, pytorch-lightning, pyro-ppl, scvi-tools, scarches\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 anndata-0.9.1 async-timeout-4.0.2 deprecated-1.2.13 docrep-0.3.2 faiss-gpu-1.7.2 frozenlist-1.3.3 igraph-0.10.4 leidenalg-0.9.1 lightning-utilities-0.8.0 ml-collections-0.1.1 mudata-0.2.2 multidict-6.0.4 muon-0.1.3 newick-1.0.0 numpyro-0.11.0 plottable-0.1.5 pynndescent-0.5.10 pyro-api-0.1.2 pyro-ppl-1.8.4 pytorch-lightning-1.9.5 scHPL-1.0.2 scanpy-1.9.3 scarches-0.5.8 scib-1.1.3 scib_metrics-0.3.3 scikit-misc-0.2.0 scvi-tools-0.20.3 scvi_colab-0.12.0 session-info-1.0.0 stdlib_list-0.8.0 texttable-1.6.7 torchmetrics-0.11.4 umap-learn-0.5.3 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install scarches scvi-tools scib scib_metrics scvi_colab faiss-gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ku_nOtvyPjCE"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6x2wAIpPgyL",
        "outputId": "dd0b8bb5-5958-4b11-ee07-11d56da1af15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:In order to use the mouse gastrulation seqFISH datsets, please install squidpy (see https://github.com/scverse/squidpy).\n",
            "WARNING:root:In order to use sagenet models, please install pytorch geometric (see https://pytorch-geometric.readthedocs.io) and \n",
            " captum (see https://github.com/pytorch/captum).\n",
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n",
            "WARNING:root:mvTCR is not installed. To use mvTCR models, please install it first using \"pip install mvtcr\"\n",
            "WARNING:root:multigrate is not installed. To use multigrate models, please install it first using \"pip install multigrate\".\n"
          ]
        }
      ],
      "source": [
        "import scanpy as sc\n",
        "import torch\n",
        "import scarches as sca\n",
        "import numpy as np\n",
        "import gdown\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdM2PFPVQK1c"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZMN1IOgQNFM"
      },
      "outputs": [],
      "source": [
        "sc.set_figure_params(frameon=False)\n",
        "sc.set_figure_params(dpi=200)\n",
        "sc.set_figure_params(figsize=(4, 4))\n",
        "torch.set_printoptions(precision=3, sci_mode=False, edgeitems=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GevfONlQQVj"
      },
      "source": [
        "### Data upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55-ZoBVhQSND",
        "outputId": "0161d505-4e18-4729-eaef-b6d6b4532c61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk1_syFgU-r3"
      },
      "outputs": [],
      "source": [
        "input_cancer = '/gdrive/MyDrive/Colab Notebooks/gut_data/cancer_integration/input_files/Epithelial_Colon_cancer_atlas_normalized.h5ad'\n",
        "adata_cancer = sc.read_h5ad(input_cancer)\n",
        "\n",
        "input_healthy = '/gdrive/MyDrive/Colab Notebooks/gut_data/cancer_integration/input_files/Epithelial_Healthy_anndata_normalized.h5ad'\n",
        "adata_healthy = sc.read_h5ad(input_healthy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh66C7Bpc7q2"
      },
      "source": [
        "### Extract Highly Variable Genes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXijxOWu9uLb"
      },
      "outputs": [],
      "source": [
        "adata_healthy.layers['raw_counts'] = adata_healthy.X.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQPzlPsW20po"
      },
      "outputs": [],
      "source": [
        "### HVGs selection\n",
        "# Calculate HVGs for cancer dataset\n",
        "sc.pp.highly_variable_genes(\n",
        "    adata_healthy,\n",
        "    flavor = \"seurat_v3\",\n",
        "    n_top_genes = 5000,\n",
        "    layer = \"raw_counts\",\n",
        "    batch_key = \"Library_Preparation_Protocol\",\n",
        "    subset = True,\n",
        "    span = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oa2rIV1adMQy"
      },
      "outputs": [],
      "source": [
        "# Extract same HVGs in the cancer dataset as in the healthy dataset\n",
        "\n",
        "#Make indexes as string\n",
        "adata_cancer.var.index = adata_cancer.var.index.astype(str)\n",
        "\n",
        "# Ensure indexes are unique\n",
        "adata_cancer.var_names_make_unique()\n",
        "\n",
        "# Identify common genes\n",
        "common_genes = list(set(adata_healthy.var_names) & set(adata_cancer.var_names))\n",
        "\n",
        "# Filter genes\n",
        "adata_healthy = adata_healthy[:, common_genes]\n",
        "adata_cancer = adata_cancer[:, common_genes]\n",
        "\n",
        "#Ensure the same order of the genes\n",
        "adata_cancer = adata_cancer[:, adata_healthy.var_names]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU-GvHwjRNfC"
      },
      "source": [
        "### Create expiMap model and train it on reference dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "XDAdX3Aa7ydj",
        "outputId": "1e763d90-3a4e-4215-dd55-a0a07dd09ade"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                        Sample_ID   Cell Type  \\\n",
              "cell_id                                                                         \n",
              "ACGAGGATCAGTGTTG-1-4918STDY7421298  BRC2043_10.2Wk_FTIL_SC-EPCAMP  Epithelial   \n",
              "H158108_N1-GTTAAGCAGAGGTAGA                            H158108_N1  Epithelial   \n",
              "H180844_N1-AACTCAGTCAAGATCC                            H180844_N1  Epithelial   \n",
              "H180844_N4-CGCTTCAGTAGGCATG                            H180844_N4  Epithelial   \n",
              "GACGCGTTCCTCAACC-1-WTDAtest7844018             A33-CAE-0-SC-45N-1  Epithelial   \n",
              "...                                                           ...         ...   \n",
              "ATCGAGTTCGGCTACG-1-WTDAtest7770719             A30-SCL-6-SC-45N-2  Epithelial   \n",
              "H180844_N1-ATAGACCTCTAACTGG                            H180844_N1  Epithelial   \n",
              "GGAACTTTCTTTACGT-1-4918STDY7421297  BRC2043_10.2Wk_FPIL_SC-EPCAMP  Epithelial   \n",
              "H180844_N4-TTTGCGCCATGCGCAC                            H180844_N4  Epithelial   \n",
              "GTCACGGAGCTGCGAA-1-4918STDY7714150             T036-TIL-SC-EPCAMP  Epithelial   \n",
              "\n",
              "                                        Study_name    Donor_ID  \\\n",
              "cell_id                                                          \n",
              "ACGAGGATCAGTGTTG-1-4918STDY7421298  Gut Cell Atlas     BRC2043   \n",
              "H158108_N1-GTTAAGCAGAGGTAGA              Kong 2023      158108   \n",
              "H180844_N1-AACTCAGTCAAGATCC              Kong 2023      180844   \n",
              "H180844_N4-CGCTTCAGTAGGCATG              Kong 2023      180844   \n",
              "GACGCGTTCCTCAACC-1-WTDAtest7844018  Gut Cell Atlas  A33 (414C)   \n",
              "...                                            ...         ...   \n",
              "ATCGAGTTCGGCTACG-1-WTDAtest7770719  Gut Cell Atlas  A30 (398B)   \n",
              "H180844_N1-ATAGACCTCTAACTGG              Kong 2023      180844   \n",
              "GGAACTTTCTTTACGT-1-4918STDY7421297  Gut Cell Atlas     BRC2043   \n",
              "H180844_N4-TTTGCGCCATGCGCAC              Kong 2023      180844   \n",
              "GTCACGGAGCTGCGAA-1-4918STDY7714150  Gut Cell Atlas     T036POS   \n",
              "\n",
              "                                            Diagnosis     Age Region code  \\\n",
              "cell_id                                                                     \n",
              "ACGAGGATCAGTGTTG-1-4918STDY7421298      Fetal Healthy  10.2Wk        FTIL   \n",
              "H158108_N1-GTTAAGCAGAGGTAGA             Healthy adult     NaN         NaN   \n",
              "H180844_N1-AACTCAGTCAAGATCC             Healthy adult     NaN         NaN   \n",
              "H180844_N4-CGCTTCAGTAGGCATG             Healthy adult     NaN         NaN   \n",
              "GACGCGTTCCTCAACC-1-WTDAtest7844018      Healthy adult   20-25         CAE   \n",
              "...                                               ...     ...         ...   \n",
              "ATCGAGTTCGGCTACG-1-WTDAtest7770719      Healthy adult   20-25         SCL   \n",
              "H180844_N1-ATAGACCTCTAACTGG             Healthy adult     NaN         NaN   \n",
              "GGAACTTTCTTTACGT-1-4918STDY7421297      Fetal Healthy  10.2Wk        FPIL   \n",
              "H180844_N4-TTTGCGCCATGCGCAC             Healthy adult     NaN         NaN   \n",
              "GTCACGGAGCTGCGAA-1-4918STDY7714150  Pediatric healthy       4         TIL   \n",
              "\n",
              "                                     Fraction  Gender  \\\n",
              "cell_id                                                 \n",
              "ACGAGGATCAGTGTTG-1-4918STDY7421298  SC-EPCAMP    Male   \n",
              "H158108_N1-GTTAAGCAGAGGTAGA               NaN    Male   \n",
              "H180844_N1-AACTCAGTCAAGATCC               NaN    Male   \n",
              "H180844_N4-CGCTTCAGTAGGCATG               NaN    Male   \n",
              "GACGCGTTCCTCAACC-1-WTDAtest7844018     SC-45N    Male   \n",
              "...                                       ...     ...   \n",
              "ATCGAGTTCGGCTACG-1-WTDAtest7770719     SC-45N  Female   \n",
              "H180844_N1-ATAGACCTCTAACTGG               NaN    Male   \n",
              "GGAACTTTCTTTACGT-1-4918STDY7421297  SC-EPCAMP    Male   \n",
              "H180844_N4-TTTGCGCCATGCGCAC               NaN    Male   \n",
              "GTCACGGAGCTGCGAA-1-4918STDY7714150  SC-EPCAMP    Male   \n",
              "\n",
              "                                   Library_Preparation_Protocol  ...  \\\n",
              "cell_id                                                          ...   \n",
              "ACGAGGATCAGTGTTG-1-4918STDY7421298                           3'  ...   \n",
              "H158108_N1-GTTAAGCAGAGGTAGA                           10x 3' v2  ...   \n",
              "H180844_N1-AACTCAGTCAAGATCC                           10x 3' v2  ...   \n",
              "H180844_N4-CGCTTCAGTAGGCATG                           10x 3' v2  ...   \n",
              "GACGCGTTCCTCAACC-1-WTDAtest7844018                           3'  ...   \n",
              "...                                                         ...  ...   \n",
              "ATCGAGTTCGGCTACG-1-WTDAtest7770719                           3'  ...   \n",
              "H180844_N1-ATAGACCTCTAACTGG                           10x 3' v2  ...   \n",
              "GGAACTTTCTTTACGT-1-4918STDY7421297                           3'  ...   \n",
              "H180844_N4-TTTGCGCCATGCGCAC                           10x 3' v2  ...   \n",
              "GTCACGGAGCTGCGAA-1-4918STDY7714150                           3'  ...   \n",
              "\n",
              "                                      dataset n_genes_by_counts total_counts  \\\n",
              "cell_id                                                                        \n",
              "ACGAGGATCAGTGTTG-1-4918STDY7421298  reference              1513       4993.0   \n",
              "H158108_N1-GTTAAGCAGAGGTAGA             query               806       2072.0   \n",
              "H180844_N1-AACTCAGTCAAGATCC             query               499        872.0   \n",
              "H180844_N4-CGCTTCAGTAGGCATG             query               768       1814.0   \n",
              "GACGCGTTCCTCAACC-1-WTDAtest7844018  reference               743       1516.0   \n",
              "...                                       ...               ...          ...   \n",
              "ATCGAGTTCGGCTACG-1-WTDAtest7770719  reference              3216      16628.0   \n",
              "H180844_N1-ATAGACCTCTAACTGG             query               379        752.0   \n",
              "GGAACTTTCTTTACGT-1-4918STDY7421297  reference              1156       3803.0   \n",
              "H180844_N4-TTTGCGCCATGCGCAC             query               407        807.0   \n",
              "GTCACGGAGCTGCGAA-1-4918STDY7714150  reference               828       1899.0   \n",
              "\n",
              "                                   total_counts_mito pct_counts_mito  \\\n",
              "cell_id                                                                \n",
              "ACGAGGATCAGTGTTG-1-4918STDY7421298             164.0        3.284599   \n",
              "H158108_N1-GTTAAGCAGAGGTAGA                     15.0        0.723938   \n",
              "H180844_N1-AACTCAGTCAAGATCC                    119.0       13.646789   \n",
              "H180844_N4-CGCTTCAGTAGGCATG                    243.0       13.395810   \n",
              "GACGCGTTCCTCAACC-1-WTDAtest7844018             109.0        7.189973   \n",
              "...                                              ...             ...   \n",
              "ATCGAGTTCGGCTACG-1-WTDAtest7770719            1578.0        9.490017   \n",
              "H180844_N1-ATAGACCTCTAACTGG                     79.0       10.505320   \n",
              "GGAACTTTCTTTACGT-1-4918STDY7421297             206.0        5.416776   \n",
              "H180844_N4-TTTGCGCCATGCGCAC                    132.0       16.356878   \n",
              "GTCACGGAGCTGCGAA-1-4918STDY7714150             267.0       14.060031   \n",
              "\n",
              "                                   total_counts_ribo pct_counts_ribo  \\\n",
              "cell_id                                                                \n",
              "ACGAGGATCAGTGTTG-1-4918STDY7421298            1969.0       39.435207   \n",
              "H158108_N1-GTTAAGCAGAGGTAGA                    185.0        8.928572   \n",
              "H180844_N1-AACTCAGTCAAGATCC                    213.0       24.426605   \n",
              "H180844_N4-CGCTTCAGTAGGCATG                     39.0        2.149945   \n",
              "GACGCGTTCCTCAACC-1-WTDAtest7844018             401.0       26.451189   \n",
              "...                                              ...             ...   \n",
              "ATCGAGTTCGGCTACG-1-WTDAtest7770719            5333.0       32.072407   \n",
              "H180844_N1-ATAGACCTCTAACTGG                    207.0       27.526596   \n",
              "GGAACTTTCTTTACGT-1-4918STDY7421297            1975.0       51.932686   \n",
              "H180844_N4-TTTGCGCCATGCGCAC                     49.0        6.071871   \n",
              "GTCACGGAGCTGCGAA-1-4918STDY7714150             246.0       12.954185   \n",
              "\n",
              "                                                               Cell_ID  \\\n",
              "cell_id                                                                  \n",
              "ACGAGGATCAGTGTTG-1-4918STDY7421298  ACGAGGATCAGTGTTG-1-4918STDY7421298   \n",
              "H158108_N1-GTTAAGCAGAGGTAGA                H158108_N1-GTTAAGCAGAGGTAGA   \n",
              "H180844_N1-AACTCAGTCAAGATCC                H180844_N1-AACTCAGTCAAGATCC   \n",
              "H180844_N4-CGCTTCAGTAGGCATG                H180844_N4-CGCTTCAGTAGGCATG   \n",
              "GACGCGTTCCTCAACC-1-WTDAtest7844018  GACGCGTTCCTCAACC-1-WTDAtest7844018   \n",
              "...                                                                ...   \n",
              "ATCGAGTTCGGCTACG-1-WTDAtest7770719  ATCGAGTTCGGCTACG-1-WTDAtest7770719   \n",
              "H180844_N1-ATAGACCTCTAACTGG                H180844_N1-ATAGACCTCTAACTGG   \n",
              "GGAACTTTCTTTACGT-1-4918STDY7421297  GGAACTTTCTTTACGT-1-4918STDY7421297   \n",
              "H180844_N4-TTTGCGCCATGCGCAC                H180844_N4-TTTGCGCCATGCGCAC   \n",
              "GTCACGGAGCTGCGAA-1-4918STDY7714150  GTCACGGAGCTGCGAA-1-4918STDY7714150   \n",
              "\n",
              "                                   _scvi_batch  _scvi_labels  \n",
              "cell_id                                                       \n",
              "ACGAGGATCAGTGTTG-1-4918STDY7421298           0             2  \n",
              "H158108_N1-GTTAAGCAGAGGTAGA                  0             2  \n",
              "H180844_N1-AACTCAGTCAAGATCC                  0             2  \n",
              "H180844_N4-CGCTTCAGTAGGCATG                  0             2  \n",
              "GACGCGTTCCTCAACC-1-WTDAtest7844018           0             2  \n",
              "...                                        ...           ...  \n",
              "ATCGAGTTCGGCTACG-1-WTDAtest7770719           0             2  \n",
              "H180844_N1-ATAGACCTCTAACTGG                  0             2  \n",
              "GGAACTTTCTTTACGT-1-4918STDY7421297           0             2  \n",
              "H180844_N4-TTTGCGCCATGCGCAC                  0             2  \n",
              "GTCACGGAGCTGCGAA-1-4918STDY7714150           0             2  \n",
              "\n",
              "[210075 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86e1050e-9427-4124-a104-c34e3f750de8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sample_ID</th>\n",
              "      <th>Cell Type</th>\n",
              "      <th>Study_name</th>\n",
              "      <th>Donor_ID</th>\n",
              "      <th>Diagnosis</th>\n",
              "      <th>Age</th>\n",
              "      <th>Region code</th>\n",
              "      <th>Fraction</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Library_Preparation_Protocol</th>\n",
              "      <th>...</th>\n",
              "      <th>dataset</th>\n",
              "      <th>n_genes_by_counts</th>\n",
              "      <th>total_counts</th>\n",
              "      <th>total_counts_mito</th>\n",
              "      <th>pct_counts_mito</th>\n",
              "      <th>total_counts_ribo</th>\n",
              "      <th>pct_counts_ribo</th>\n",
              "      <th>Cell_ID</th>\n",
              "      <th>_scvi_batch</th>\n",
              "      <th>_scvi_labels</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cell_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ACGAGGATCAGTGTTG-1-4918STDY7421298</th>\n",
              "      <td>BRC2043_10.2Wk_FTIL_SC-EPCAMP</td>\n",
              "      <td>Epithelial</td>\n",
              "      <td>Gut Cell Atlas</td>\n",
              "      <td>BRC2043</td>\n",
              "      <td>Fetal Healthy</td>\n",
              "      <td>10.2Wk</td>\n",
              "      <td>FTIL</td>\n",
              "      <td>SC-EPCAMP</td>\n",
              "      <td>Male</td>\n",
              "      <td>3'</td>\n",
              "      <td>...</td>\n",
              "      <td>reference</td>\n",
              "      <td>1513</td>\n",
              "      <td>4993.0</td>\n",
              "      <td>164.0</td>\n",
              "      <td>3.284599</td>\n",
              "      <td>1969.0</td>\n",
              "      <td>39.435207</td>\n",
              "      <td>ACGAGGATCAGTGTTG-1-4918STDY7421298</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H158108_N1-GTTAAGCAGAGGTAGA</th>\n",
              "      <td>H158108_N1</td>\n",
              "      <td>Epithelial</td>\n",
              "      <td>Kong 2023</td>\n",
              "      <td>158108</td>\n",
              "      <td>Healthy adult</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Male</td>\n",
              "      <td>10x 3' v2</td>\n",
              "      <td>...</td>\n",
              "      <td>query</td>\n",
              "      <td>806</td>\n",
              "      <td>2072.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.723938</td>\n",
              "      <td>185.0</td>\n",
              "      <td>8.928572</td>\n",
              "      <td>H158108_N1-GTTAAGCAGAGGTAGA</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H180844_N1-AACTCAGTCAAGATCC</th>\n",
              "      <td>H180844_N1</td>\n",
              "      <td>Epithelial</td>\n",
              "      <td>Kong 2023</td>\n",
              "      <td>180844</td>\n",
              "      <td>Healthy adult</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Male</td>\n",
              "      <td>10x 3' v2</td>\n",
              "      <td>...</td>\n",
              "      <td>query</td>\n",
              "      <td>499</td>\n",
              "      <td>872.0</td>\n",
              "      <td>119.0</td>\n",
              "      <td>13.646789</td>\n",
              "      <td>213.0</td>\n",
              "      <td>24.426605</td>\n",
              "      <td>H180844_N1-AACTCAGTCAAGATCC</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H180844_N4-CGCTTCAGTAGGCATG</th>\n",
              "      <td>H180844_N4</td>\n",
              "      <td>Epithelial</td>\n",
              "      <td>Kong 2023</td>\n",
              "      <td>180844</td>\n",
              "      <td>Healthy adult</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Male</td>\n",
              "      <td>10x 3' v2</td>\n",
              "      <td>...</td>\n",
              "      <td>query</td>\n",
              "      <td>768</td>\n",
              "      <td>1814.0</td>\n",
              "      <td>243.0</td>\n",
              "      <td>13.395810</td>\n",
              "      <td>39.0</td>\n",
              "      <td>2.149945</td>\n",
              "      <td>H180844_N4-CGCTTCAGTAGGCATG</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GACGCGTTCCTCAACC-1-WTDAtest7844018</th>\n",
              "      <td>A33-CAE-0-SC-45N-1</td>\n",
              "      <td>Epithelial</td>\n",
              "      <td>Gut Cell Atlas</td>\n",
              "      <td>A33 (414C)</td>\n",
              "      <td>Healthy adult</td>\n",
              "      <td>20-25</td>\n",
              "      <td>CAE</td>\n",
              "      <td>SC-45N</td>\n",
              "      <td>Male</td>\n",
              "      <td>3'</td>\n",
              "      <td>...</td>\n",
              "      <td>reference</td>\n",
              "      <td>743</td>\n",
              "      <td>1516.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>7.189973</td>\n",
              "      <td>401.0</td>\n",
              "      <td>26.451189</td>\n",
              "      <td>GACGCGTTCCTCAACC-1-WTDAtest7844018</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ATCGAGTTCGGCTACG-1-WTDAtest7770719</th>\n",
              "      <td>A30-SCL-6-SC-45N-2</td>\n",
              "      <td>Epithelial</td>\n",
              "      <td>Gut Cell Atlas</td>\n",
              "      <td>A30 (398B)</td>\n",
              "      <td>Healthy adult</td>\n",
              "      <td>20-25</td>\n",
              "      <td>SCL</td>\n",
              "      <td>SC-45N</td>\n",
              "      <td>Female</td>\n",
              "      <td>3'</td>\n",
              "      <td>...</td>\n",
              "      <td>reference</td>\n",
              "      <td>3216</td>\n",
              "      <td>16628.0</td>\n",
              "      <td>1578.0</td>\n",
              "      <td>9.490017</td>\n",
              "      <td>5333.0</td>\n",
              "      <td>32.072407</td>\n",
              "      <td>ATCGAGTTCGGCTACG-1-WTDAtest7770719</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H180844_N1-ATAGACCTCTAACTGG</th>\n",
              "      <td>H180844_N1</td>\n",
              "      <td>Epithelial</td>\n",
              "      <td>Kong 2023</td>\n",
              "      <td>180844</td>\n",
              "      <td>Healthy adult</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Male</td>\n",
              "      <td>10x 3' v2</td>\n",
              "      <td>...</td>\n",
              "      <td>query</td>\n",
              "      <td>379</td>\n",
              "      <td>752.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>10.505320</td>\n",
              "      <td>207.0</td>\n",
              "      <td>27.526596</td>\n",
              "      <td>H180844_N1-ATAGACCTCTAACTGG</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GGAACTTTCTTTACGT-1-4918STDY7421297</th>\n",
              "      <td>BRC2043_10.2Wk_FPIL_SC-EPCAMP</td>\n",
              "      <td>Epithelial</td>\n",
              "      <td>Gut Cell Atlas</td>\n",
              "      <td>BRC2043</td>\n",
              "      <td>Fetal Healthy</td>\n",
              "      <td>10.2Wk</td>\n",
              "      <td>FPIL</td>\n",
              "      <td>SC-EPCAMP</td>\n",
              "      <td>Male</td>\n",
              "      <td>3'</td>\n",
              "      <td>...</td>\n",
              "      <td>reference</td>\n",
              "      <td>1156</td>\n",
              "      <td>3803.0</td>\n",
              "      <td>206.0</td>\n",
              "      <td>5.416776</td>\n",
              "      <td>1975.0</td>\n",
              "      <td>51.932686</td>\n",
              "      <td>GGAACTTTCTTTACGT-1-4918STDY7421297</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>H180844_N4-TTTGCGCCATGCGCAC</th>\n",
              "      <td>H180844_N4</td>\n",
              "      <td>Epithelial</td>\n",
              "      <td>Kong 2023</td>\n",
              "      <td>180844</td>\n",
              "      <td>Healthy adult</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Male</td>\n",
              "      <td>10x 3' v2</td>\n",
              "      <td>...</td>\n",
              "      <td>query</td>\n",
              "      <td>407</td>\n",
              "      <td>807.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>16.356878</td>\n",
              "      <td>49.0</td>\n",
              "      <td>6.071871</td>\n",
              "      <td>H180844_N4-TTTGCGCCATGCGCAC</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GTCACGGAGCTGCGAA-1-4918STDY7714150</th>\n",
              "      <td>T036-TIL-SC-EPCAMP</td>\n",
              "      <td>Epithelial</td>\n",
              "      <td>Gut Cell Atlas</td>\n",
              "      <td>T036POS</td>\n",
              "      <td>Pediatric healthy</td>\n",
              "      <td>4</td>\n",
              "      <td>TIL</td>\n",
              "      <td>SC-EPCAMP</td>\n",
              "      <td>Male</td>\n",
              "      <td>3'</td>\n",
              "      <td>...</td>\n",
              "      <td>reference</td>\n",
              "      <td>828</td>\n",
              "      <td>1899.0</td>\n",
              "      <td>267.0</td>\n",
              "      <td>14.060031</td>\n",
              "      <td>246.0</td>\n",
              "      <td>12.954185</td>\n",
              "      <td>GTCACGGAGCTGCGAA-1-4918STDY7714150</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>210075 rows × 28 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86e1050e-9427-4124-a104-c34e3f750de8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86e1050e-9427-4124-a104-c34e3f750de8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86e1050e-9427-4124-a104-c34e3f750de8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "adata_healthy.obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UxmVFGT6ROSE"
      },
      "outputs": [],
      "source": [
        "# Create a mask with all ones (assuming all genes are equally important)\n",
        "adata_healthy.varm['mask'] = np.ones((adata_healthy.n_vars, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuZLw0doRXtd",
        "outputId": "3531bfdc-af8f-47e5-80bf-0abc6aff73ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "INITIALIZING NEW NETWORK..............\n",
            "Encoder Architecture:\n",
            "\tInput Layer in, out and cond: 4655 256 296\n",
            "\tHidden Layer 1 in/out: 256 256\n",
            "\tHidden Layer 2 in/out: 256 256\n",
            "\tMean/Var Layer in/out: 256 1\n",
            "Decoder Architecture:\n",
            "\tMasked linear layer in, ext_m, ext, cond, out:  1 0 0 296 4655\n",
            "\twith hard mask.\n",
            "Last Decoder layer: softmax\n"
          ]
        }
      ],
      "source": [
        "intr_cvae = sca.models.EXPIMAP(\n",
        "    adata = adata_healthy,\n",
        "    condition_key='Sample_ID',\n",
        "    hidden_layer_sizes=[256, 256, 256],\n",
        "    recon_loss='nb',\n",
        "    mask_key='mask'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcCdydHnRZ2t"
      },
      "outputs": [],
      "source": [
        "ALPHA = 0.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LfHaKGWFJZx",
        "outputId": "8a90973d-c3ae-45b9-eabe-672973dcb7bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVftvLufGFUt",
        "outputId": "5595ce9b-4e70-43d6-c235-f52f439bd6a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "expiMap(\n",
              "  (encoder): ExtEncoder(\n",
              "    (FC): Sequential(\n",
              "      (L0): MaskedCondLayers(\n",
              "        (expr_L): Linear(in_features=4655, out_features=256, bias=True)\n",
              "        (cond_L): Linear(in_features=296, out_features=256, bias=False)\n",
              "      )\n",
              "      (N0): LayerNorm((256,), eps=1e-05, elementwise_affine=False)\n",
              "      (A0): ReLU()\n",
              "      (D0): Dropout(p=0.05, inplace=False)\n",
              "      (L1): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (N1): LayerNorm((256,), eps=1e-05, elementwise_affine=False)\n",
              "      (A1): ReLU()\n",
              "      (D1): Dropout(p=0.05, inplace=False)\n",
              "      (L2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (N2): LayerNorm((256,), eps=1e-05, elementwise_affine=False)\n",
              "      (A2): ReLU()\n",
              "      (D2): Dropout(p=0.05, inplace=False)\n",
              "    )\n",
              "    (mean_encoder): Linear(in_features=256, out_features=1, bias=True)\n",
              "    (log_var_encoder): Linear(in_features=256, out_features=1, bias=True)\n",
              "  )\n",
              "  (decoder): MaskedLinearDecoder(\n",
              "    (L0): MaskedCondLayers(\n",
              "      (expr_L): MaskedLinear(in_features=1, out_features=4655, bias=False)\n",
              "      (cond_L): Linear(in_features=296, out_features=4655, bias=False)\n",
              "    )\n",
              "    (mean_decoder): Softmax(dim=-1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "intr_cvae.model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzqXfpf_SjTs",
        "outputId": "27e0bc47-6445-460d-c286-c785aa101969"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init the group lasso proximal operator for the main terms.\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 0.5%  - epoch_loss: 827.3853559617 - epoch_recon_loss: 827.3853559617 - epoch_kl_loss: 9.0667736573 - val_loss: 712.1950932945 - val_recon_loss: 712.1950932945 - val_kl_loss: 16.5384059941\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 1.0%  - epoch_loss: 712.4422618564 - epoch_recon_loss: 712.3488878066 - epoch_kl_loss: 18.6747933543 - val_loss: 708.5985717773 - val_recon_loss: 708.4958566805 - val_kl_loss: 20.5425506220\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 1.5%  - epoch_loss: 709.9705946318 - epoch_recon_loss: 709.7636091066 - epoch_kl_loss: 20.6984945972 - val_loss: 708.2130160448 - val_recon_loss: 707.9980491080 - val_kl_loss: 21.4967727894\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 2.0%  - epoch_loss: 702.9562443133 - epoch_recon_loss: 702.6336147471 - epoch_kl_loss: 21.5086928620 - val_loss: 707.9165601033 - val_recon_loss: 707.5837506550 - val_kl_loss: 22.1873277920\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 2.5%  - epoch_loss: 700.9221650717 - epoch_recon_loss: 700.4917190273 - epoch_kl_loss: 21.5222610064 - val_loss: 706.9678456376 - val_recon_loss: 706.5304271419 - val_kl_loss: 21.8709232400\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 3.0%  - epoch_loss: 697.2863485196 - epoch_recon_loss: 696.7554986114 - epoch_kl_loss: 21.2339613014 - val_loss: 707.3705794172 - val_recon_loss: 706.8441117450 - val_kl_loss: 21.0588038142\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 3.5%  - epoch_loss: 693.7072696544 - epoch_recon_loss: 693.0876851936 - epoch_kl_loss: 20.6528130738 - val_loss: 706.8942178866 - val_recon_loss: 706.2701043850 - val_kl_loss: 20.8038223429\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 4.0%  - epoch_loss: 689.5650132949 - epoch_recon_loss: 688.8672401165 - epoch_kl_loss: 19.9363732444 - val_loss: 704.5422534477 - val_recon_loss: 703.8693218696 - val_kl_loss: 19.2266075320\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |--------------------| 4.5%  - epoch_loss: 689.9022242796 - epoch_recon_loss: 689.1370057267 - epoch_kl_loss: 19.1304434982 - val_loss: 704.9662613287 - val_recon_loss: 704.2059657399 - val_kl_loss: 19.0073638311\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 5.0%  - epoch_loss: 684.6254088819 - epoch_recon_loss: 683.8017262013 - epoch_kl_loss: 18.3040733092 - val_loss: 703.9688329929 - val_recon_loss: 703.1486440519 - val_kl_loss: 18.2264279505\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 5.5%  - epoch_loss: 682.6938166228 - epoch_recon_loss: 681.8182207150 - epoch_kl_loss: 17.5119237249 - val_loss: 703.4680838236 - val_recon_loss: 702.6122492348 - val_kl_loss: 17.1167577999\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 6.0%  - epoch_loss: 682.8969294901 - epoch_recon_loss: 681.9787664923 - epoch_kl_loss: 16.6938698635 - val_loss: 702.0631698981 - val_recon_loss: 701.1793797191 - val_kl_loss: 16.0689581371\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 6.5%  - epoch_loss: 680.2150477783 - epoch_recon_loss: 679.2585807424 - epoch_kl_loss: 15.9411164168 - val_loss: 702.2318286431 - val_recon_loss: 701.2834882038 - val_kl_loss: 15.8056617539\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 7.0%  - epoch_loss: 680.1176491222 - epoch_recon_loss: 679.1273045620 - epoch_kl_loss: 15.2360668898 - val_loss: 702.5063383521 - val_recon_loss: 701.5104213808 - val_kl_loss: 15.3217780997\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 7.5%  - epoch_loss: 677.7590714584 - epoch_recon_loss: 676.7385229146 - epoch_kl_loss: 14.5792691055 - val_loss: 700.3648722579 - val_recon_loss: 699.3661722323 - val_kl_loss: 14.2671488204\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 8.0%  - epoch_loss: 674.7526719285 - epoch_recon_loss: 673.7070770161 - epoch_kl_loss: 13.9412713899 - val_loss: 699.7434122969 - val_recon_loss: 698.7055812929 - val_kl_loss: 13.8377462771\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 8.5%  - epoch_loss: 673.3327778680 - epoch_recon_loss: 672.2641487251 - epoch_kl_loss: 13.3578638866 - val_loss: 699.5393903779 - val_recon_loss: 698.4909950815 - val_kl_loss: 13.1049350006\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 9.0%  - epoch_loss: 672.1558373215 - epoch_recon_loss: 671.0645066494 - epoch_kl_loss: 12.8391861235 - val_loss: 700.1075290587 - val_recon_loss: 699.0335674751 - val_kl_loss: 12.6348087497\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█-------------------| 9.5%  - epoch_loss: 671.8760775037 - epoch_recon_loss: 670.7641382430 - epoch_kl_loss: 12.3548710528 - val_loss: 699.0402050484 - val_recon_loss: 697.9415487894 - val_kl_loss: 12.2072937605\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 10.0%  - epoch_loss: 669.6091650704 - epoch_recon_loss: 668.4791926241 - epoch_kl_loss: 11.8944374694 - val_loss: 698.7478488829 - val_recon_loss: 697.6287912508 - val_kl_loss: 11.7795553149\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 10.5%  - epoch_loss: 669.7162700496 - epoch_recon_loss: 668.5659354663 - epoch_kl_loss: 11.5033379491 - val_loss: 698.3242712253 - val_recon_loss: 697.1970590731 - val_kl_loss: 11.2721201094\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 11.0%  - epoch_loss: 668.8554192698 - epoch_recon_loss: 667.6910777991 - epoch_kl_loss: 11.0889591007 - val_loss: 699.7352440066 - val_recon_loss: 698.6058907858 - val_kl_loss: 10.7557462076\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 11.5%  - epoch_loss: 667.4755420698 - epoch_recon_loss: 666.2960616519 - epoch_kl_loss: 10.7225491058 - val_loss: 698.4927550525 - val_recon_loss: 697.3031686922 - val_kl_loss: 10.8144196359\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 12.0%  - epoch_loss: 666.2100757859 - epoch_recon_loss: 665.0128276585 - epoch_kl_loss: 10.4108525438 - val_loss: 697.1324909489 - val_recon_loss: 695.9694638136 - val_kl_loss: 10.1132716667\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 12.5%  - epoch_loss: 665.9365659847 - epoch_recon_loss: 664.7257476250 - epoch_kl_loss: 10.0901524626 - val_loss: 696.9738196396 - val_recon_loss: 695.7628270591 - val_kl_loss: 10.0915917769\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 13.0%  - epoch_loss: 665.2439372983 - epoch_recon_loss: 664.0166524870 - epoch_kl_loss: 9.8182766562 - val_loss: 697.7520871046 - val_recon_loss: 696.5883729516 - val_kl_loss: 9.3097294424\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 13.5%  - epoch_loss: 663.5944323640 - epoch_recon_loss: 662.3566373731 - epoch_kl_loss: 9.5215023214 - val_loss: 696.6192980510 - val_recon_loss: 695.3729556944 - val_kl_loss: 9.5872569666\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 14.0%  - epoch_loss: 663.9874256848 - epoch_recon_loss: 662.7352335364 - epoch_kl_loss: 9.2755024299 - val_loss: 695.7504599967 - val_recon_loss: 694.5265822992 - val_kl_loss: 9.0657590366\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██------------------| 14.5%  - epoch_loss: 662.2297392169 - epoch_recon_loss: 660.9651264348 - epoch_kl_loss: 9.0329545629 - val_loss: 695.4766004609 - val_recon_loss: 694.2473010552 - val_kl_loss: 8.7807029893\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 15.0%  - epoch_loss: 662.7871030198 - epoch_recon_loss: 661.5059080298 - epoch_kl_loss: 8.8358327280 - val_loss: 695.6081587629 - val_recon_loss: 694.3456234816 - val_kl_loss: 8.7071366339\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 15.5%  - epoch_loss: 662.4840682973 - epoch_recon_loss: 661.1895092080 - epoch_kl_loss: 8.6303949727 - val_loss: 695.3962275807 - val_recon_loss: 694.1294641262 - val_kl_loss: 8.4450962863\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 16.0%  - epoch_loss: 661.0506771725 - epoch_recon_loss: 659.7434115046 - epoch_kl_loss: 8.4339715559 - val_loss: 695.0516409525 - val_recon_loss: 693.7661728277 - val_kl_loss: 8.2933387960\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 16.5%  - epoch_loss: 660.1996936605 - epoch_recon_loss: 658.8808562593 - epoch_kl_loss: 8.2427349887 - val_loss: 695.3802151564 - val_recon_loss: 694.1003648711 - val_kl_loss: 7.9990716329\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 17.0%  - epoch_loss: 658.9756564230 - epoch_recon_loss: 657.6438707167 - epoch_kl_loss: 8.0714271518 - val_loss: 694.2107309481 - val_recon_loss: 692.8917854123 - val_kl_loss: 7.9936166042\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 17.5%  - epoch_loss: 657.7237756405 - epoch_recon_loss: 656.3767443303 - epoch_kl_loss: 7.9237151755 - val_loss: 695.2271285639 - val_recon_loss: 693.9078841791 - val_kl_loss: 7.7602604482\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 18.0%  - epoch_loss: 657.1019030423 - epoch_recon_loss: 655.7412561671 - epoch_kl_loss: 7.7751252388 - val_loss: 694.6395829364 - val_recon_loss: 693.3061035901 - val_kl_loss: 7.6198798302\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 18.5%  - epoch_loss: 658.5770444012 - epoch_recon_loss: 657.2040543933 - epoch_kl_loss: 7.6277237806 - val_loss: 693.0116071003 - val_recon_loss: 691.6645213802 - val_kl_loss: 7.4838041620\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 19.0%  - epoch_loss: 656.6318339566 - epoch_recon_loss: 655.2444049869 - epoch_kl_loss: 7.4996128592 - val_loss: 694.3898441966 - val_recon_loss: 693.0282499732 - val_kl_loss: 7.3599697468\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███-----------------| 19.5%  - epoch_loss: 656.4671874340 - epoch_recon_loss: 655.0668308137 - epoch_kl_loss: 7.3702966985 - val_loss: 695.5549535984 - val_recon_loss: 694.1809256949 - val_kl_loss: 7.2317312520\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 20.0%  - epoch_loss: 655.5306844241 - epoch_recon_loss: 654.1191250258 - epoch_kl_loss: 7.2387689535 - val_loss: 693.4293793469 - val_recon_loss: 692.0463107970 - val_kl_loss: 7.0926683124\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 20.5%  - epoch_loss: 655.0153160688 - epoch_recon_loss: 653.5903325677 - epoch_kl_loss: 7.1249153003 - val_loss: 692.9098935011 - val_recon_loss: 691.5192562196 - val_kl_loss: 6.9531816302\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 21.0%  - epoch_loss: 654.5270603636 - epoch_recon_loss: 653.0869418358 - epoch_kl_loss: 7.0249666720 - val_loss: 692.3658112317 - val_recon_loss: 690.9696979057 - val_kl_loss: 6.8103087007\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 21.5%  - epoch_loss: 653.9434039030 - epoch_recon_loss: 652.4929242550 - epoch_kl_loss: 6.9070449543 - val_loss: 692.4184663354 - val_recon_loss: 690.9992441317 - val_kl_loss: 6.7581929695\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 22.0%  - epoch_loss: 653.2555775568 - epoch_recon_loss: 651.7909481108 - epoch_kl_loss: 6.8122243265 - val_loss: 694.3391478004 - val_recon_loss: 692.9244600622 - val_kl_loss: 6.5799427236\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 22.5%  - epoch_loss: 653.8932751803 - epoch_recon_loss: 652.4150141780 - epoch_kl_loss: 6.7193660752 - val_loss: 692.8259954685 - val_recon_loss: 691.3815880752 - val_kl_loss: 6.5654849948\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 23.0%  - epoch_loss: 652.9455217693 - epoch_recon_loss: 651.4526982079 - epoch_kl_loss: 6.6347728198 - val_loss: 691.8258503239 - val_recon_loss: 690.3775977158 - val_kl_loss: 6.4366817300\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 23.5%  - epoch_loss: 654.0639475938 - epoch_recon_loss: 652.5578492779 - epoch_kl_loss: 6.5482548397 - val_loss: 693.3853268507 - val_recon_loss: 691.9042972472 - val_kl_loss: 6.4392551591\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 24.0%  - epoch_loss: 650.5946950339 - epoch_recon_loss: 649.0759180364 - epoch_kl_loss: 6.4628803271 - val_loss: 692.0731256997 - val_recon_loss: 690.5877644609 - val_kl_loss: 6.3206777456\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████----------------| 24.5%  - epoch_loss: 651.6287407659 - epoch_recon_loss: 650.0979330335 - epoch_kl_loss: 6.3783679918 - val_loss: 691.5269403225 - val_recon_loss: 690.0491202750 - val_kl_loss: 6.1575807653\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 25.0%  - epoch_loss: 650.8758736405 - epoch_recon_loss: 649.3299222976 - epoch_kl_loss: 6.3100048566 - val_loss: 691.2597604147 - val_recon_loss: 689.7633946116 - val_kl_loss: 6.1076174160\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 25.5%  - epoch_loss: 651.7830290159 - epoch_recon_loss: 650.2252872820 - epoch_kl_loss: 6.2309681104 - val_loss: 691.8407804908 - val_recon_loss: 690.3269296041 - val_kl_loss: 6.0553876278\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 26.0%  - epoch_loss: 650.2704996415 - epoch_recon_loss: 648.6960651431 - epoch_kl_loss: 6.1742540350 - val_loss: 690.6063221257 - val_recon_loss: 689.0777271550 - val_kl_loss: 5.9944879863\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 26.5%  - epoch_loss: 650.2975397839 - epoch_recon_loss: 648.7107075968 - epoch_kl_loss: 6.1032012197 - val_loss: 690.2197291677 - val_recon_loss: 688.6699590916 - val_kl_loss: 5.9606513948\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 27.0%  - epoch_loss: 648.5004527496 - epoch_recon_loss: 646.9005101780 - epoch_kl_loss: 6.0375238761 - val_loss: 692.0832463706 - val_recon_loss: 690.5307732559 - val_kl_loss: 5.8583889764\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 27.5%  - epoch_loss: 649.5228678798 - epoch_recon_loss: 647.9114572604 - epoch_kl_loss: 5.9681900961 - val_loss: 689.9224555783 - val_recon_loss: 688.3620482654 - val_kl_loss: 5.7792825321\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 28.0%  - epoch_loss: 649.2708155882 - epoch_recon_loss: 647.6446089161 - epoch_kl_loss: 5.9134796538 - val_loss: 691.4746458472 - val_recon_loss: 689.8849680831 - val_kl_loss: 5.7806473389\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 28.5%  - epoch_loss: 648.8775266244 - epoch_recon_loss: 647.2340576089 - epoch_kl_loss: 5.8695314100 - val_loss: 689.8633694532 - val_recon_loss: 688.2542869754 - val_kl_loss: 5.7467296094\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 29.0%  - epoch_loss: 649.4773532334 - epoch_recon_loss: 647.8208642925 - epoch_kl_loss: 5.8122440577 - val_loss: 690.7856374601 - val_recon_loss: 689.1967133313 - val_kl_loss: 5.5751750498\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████---------------| 29.5%  - epoch_loss: 648.2208601905 - epoch_recon_loss: 646.5499128093 - epoch_kl_loss: 5.7618896792 - val_loss: 689.9084461491 - val_recon_loss: 688.2755834068 - val_kl_loss: 5.6305589705\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 30.0%  - epoch_loss: 646.8677714814 - epoch_recon_loss: 645.1844156406 - epoch_kl_loss: 5.7062905675 - val_loss: 689.8869833597 - val_recon_loss: 688.2682982654 - val_kl_loss: 5.4870708279\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 30.5%  - epoch_loss: 645.9887042042 - epoch_recon_loss: 644.2877499346 - epoch_kl_loss: 5.6698471292 - val_loss: 688.8603069026 - val_recon_loss: 687.2263246862 - val_kl_loss: 5.4466168793\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 31.0%  - epoch_loss: 647.3521984789 - epoch_recon_loss: 645.6382138018 - epoch_kl_loss: 5.6196214545 - val_loss: 688.1569597198 - val_recon_loss: 686.4804486531 - val_kl_loss: 5.4967566409\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 31.5%  - epoch_loss: 647.4098559438 - epoch_recon_loss: 645.6844105234 - epoch_kl_loss: 5.5659519818 - val_loss: 688.8002293284 - val_recon_loss: 687.1213780845 - val_kl_loss: 5.4156452970\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 32.0%  - epoch_loss: 645.9282677620 - epoch_recon_loss: 644.1874194451 - epoch_kl_loss: 5.5265029039 - val_loss: 689.2418771139 - val_recon_loss: 687.5153533191 - val_kl_loss: 5.4810277718\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 32.5%  - epoch_loss: 645.8888915438 - epoch_recon_loss: 644.1343841862 - epoch_kl_loss: 5.4828346915 - val_loss: 687.8966901826 - val_recon_loss: 686.1946734917 - val_kl_loss: 5.3187948029\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 33.0%  - epoch_loss: 645.8675893251 - epoch_recon_loss: 644.0962882206 - epoch_kl_loss: 5.4501580512 - val_loss: 686.5541489764 - val_recon_loss: 684.8455172283 - val_kl_loss: 5.2573322697\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 33.5%  - epoch_loss: 644.7119866527 - epoch_recon_loss: 642.9272403575 - epoch_kl_loss: 5.4083224126 - val_loss: 688.1513552782 - val_recon_loss: 686.3887083472 - val_kl_loss: 5.3413507909\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 34.0%  - epoch_loss: 645.9675862465 - epoch_recon_loss: 644.1674466704 - epoch_kl_loss: 5.3735523056 - val_loss: 687.3873893924 - val_recon_loss: 685.6417459627 - val_kl_loss: 5.2108718913\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████--------------| 34.5%  - epoch_loss: 644.9155852838 - epoch_recon_loss: 643.0968648564 - epoch_kl_loss: 5.3491773264 - val_loss: 686.2865820164 - val_recon_loss: 684.5352615729 - val_kl_loss: 5.1509416336\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 35.0%  - epoch_loss: 644.1146683038 - epoch_recon_loss: 642.2879182249 - epoch_kl_loss: 5.2949270454 - val_loss: 687.2144034781 - val_recon_loss: 685.4233212355 - val_kl_loss: 5.1915448352\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 35.5%  - epoch_loss: 643.8741087794 - epoch_recon_loss: 642.0308825923 - epoch_kl_loss: 5.2663607165 - val_loss: 686.9129809868 - val_recon_loss: 685.1325780357 - val_kl_loss: 5.0868673034\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 36.0%  - epoch_loss: 643.2604390338 - epoch_recon_loss: 641.3992485371 - epoch_kl_loss: 5.2427900613 - val_loss: 687.4229803318 - val_recon_loss: 685.6211730213 - val_kl_loss: 5.0755071640\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 36.5%  - epoch_loss: 644.6621967390 - epoch_recon_loss: 642.7875015021 - epoch_kl_loss: 5.2074891384 - val_loss: 686.7048444050 - val_recon_loss: 684.8714878734 - val_kl_loss: 5.0926642331\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 37.0%  - epoch_loss: 643.0448152801 - epoch_recon_loss: 641.1542507375 - epoch_kl_loss: 5.1796285695 - val_loss: 687.1761921208 - val_recon_loss: 685.3338503954 - val_kl_loss: 5.0475122085\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 37.5%  - epoch_loss: 641.5473753315 - epoch_recon_loss: 639.6439790448 - epoch_kl_loss: 5.1443143107 - val_loss: 685.7294058451 - val_recon_loss: 683.8718894400 - val_kl_loss: 5.0203077793\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 38.0%  - epoch_loss: 642.5227987974 - epoch_recon_loss: 640.6019562366 - epoch_kl_loss: 5.1222468241 - val_loss: 686.2382533376 - val_recon_loss: 684.3894679372 - val_kl_loss: 4.9300937711\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 38.5%  - epoch_loss: 642.5051808902 - epoch_recon_loss: 640.5701195728 - epoch_kl_loss: 5.0922661392 - val_loss: 686.4970691960 - val_recon_loss: 684.5969681158 - val_kl_loss: 5.0002641329\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 39.0%  - epoch_loss: 642.0952340746 - epoch_recon_loss: 640.1453888785 - epoch_kl_loss: 5.0645322171 - val_loss: 684.5257158977 - val_recon_loss: 682.6114795964 - val_kl_loss: 4.9720438079\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████-------------| 39.5%  - epoch_loss: 641.7334659517 - epoch_recon_loss: 639.7659707421 - epoch_kl_loss: 5.0448587191 - val_loss: 684.1503068877 - val_recon_loss: 682.2498939328 - val_kl_loss: 4.8728525522\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 40.0%  - epoch_loss: 639.7649061965 - epoch_recon_loss: 637.7837652344 - epoch_kl_loss: 5.0155465966 - val_loss: 684.0971594089 - val_recon_loss: 682.1930586652 - val_kl_loss: 4.8205042234\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 40.5%  - epoch_loss: 639.3477856660 - epoch_recon_loss: 637.3493928013 - epoch_kl_loss: 4.9959820950 - val_loss: 684.2374114990 - val_recon_loss: 682.3130642030 - val_kl_loss: 4.8108732846\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 41.0%  - epoch_loss: 640.5655273685 - epoch_recon_loss: 638.5495080129 - epoch_kl_loss: 4.9778279136 - val_loss: 684.2218750744 - val_recon_loss: 682.2731040396 - val_kl_loss: 4.8117839447\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 41.5%  - epoch_loss: 638.5413902546 - epoch_recon_loss: 636.5122973666 - epoch_kl_loss: 4.9490075128 - val_loss: 683.4360865151 - val_recon_loss: 681.4636107654 - val_kl_loss: 4.8109165924\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 42.0%  - epoch_loss: 639.2661736561 - epoch_recon_loss: 637.2205584812 - epoch_kl_loss: 4.9291933191 - val_loss: 683.7984414450 - val_recon_loss: 681.7867904291 - val_kl_loss: 4.8473481202\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 42.5%  - epoch_loss: 638.5090177277 - epoch_recon_loss: 636.4488041731 - epoch_kl_loss: 4.9052708895 - val_loss: 682.6862394752 - val_recon_loss: 680.6927702369 - val_kl_loss: 4.7463552254\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 43.0%  - epoch_loss: 638.7289290051 - epoch_recon_loss: 636.6498051167 - epoch_kl_loss: 4.8920555160 - val_loss: 682.1768724395 - val_recon_loss: 680.1578793409 - val_kl_loss: 4.7505736322\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 43.5%  - epoch_loss: 639.1982257216 - epoch_recon_loss: 637.1076541305 - epoch_kl_loss: 4.8617931879 - val_loss: 681.7494715249 - val_recon_loss: 679.7221024676 - val_kl_loss: 4.7148095020\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 44.0%  - epoch_loss: 636.3365213163 - epoch_recon_loss: 634.2243594156 - epoch_kl_loss: 4.8555442982 - val_loss: 681.5830547054 - val_recon_loss: 679.5142312399 - val_kl_loss: 4.7559209568\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████------------| 44.5%  - epoch_loss: 637.6766906697 - epoch_recon_loss: 635.5497607372 - epoch_kl_loss: 4.8339314325 - val_loss: 680.8143131907 - val_recon_loss: 678.7623000726 - val_kl_loss: 4.6636632594\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 45.0%  - epoch_loss: 637.5168282056 - epoch_recon_loss: 635.3760371437 - epoch_kl_loss: 4.8107659799 - val_loss: 683.2696067996 - val_recon_loss: 681.1631797232 - val_kl_loss: 4.7335425325\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 45.5%  - epoch_loss: 637.0938530046 - epoch_recon_loss: 634.9371240911 - epoch_kl_loss: 4.7927269597 - val_loss: 681.7047647616 - val_recon_loss: 679.6205983976 - val_kl_loss: 4.6314847586\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 46.0%  - epoch_loss: 636.4798071438 - epoch_recon_loss: 634.3050473557 - epoch_kl_loss: 4.7796919731 - val_loss: 681.1310030309 - val_recon_loss: 679.0261602634 - val_kl_loss: 4.6260274271\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 46.5%  - epoch_loss: 636.3614798256 - epoch_recon_loss: 634.1682251059 - epoch_kl_loss: 4.7679449688 - val_loss: 680.7528396234 - val_recon_loss: 678.6489838391 - val_kl_loss: 4.5735963932\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 47.0%  - epoch_loss: 635.4364013053 - epoch_recon_loss: 633.2261290225 - epoch_kl_loss: 4.7532730320 - val_loss: 679.7469437762 - val_recon_loss: 677.5452132807 - val_kl_loss: 4.7349028384\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 47.5%  - epoch_loss: 634.9732975525 - epoch_recon_loss: 632.7488393003 - epoch_kl_loss: 4.7328907262 - val_loss: 680.8037660180 - val_recon_loss: 678.6364109691 - val_kl_loss: 4.6113914600\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 48.0%  - epoch_loss: 634.7118236446 - epoch_recon_loss: 632.4663472205 - epoch_kl_loss: 4.7273198722 - val_loss: 678.4282133521 - val_recon_loss: 676.2520815221 - val_kl_loss: 4.5813353323\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 48.5%  - epoch_loss: 635.3851820176 - epoch_recon_loss: 633.1233956709 - epoch_kl_loss: 4.7120560371 - val_loss: 679.3592774926 - val_recon_loss: 677.1463924501 - val_kl_loss: 4.6101774820\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 49.0%  - epoch_loss: 633.0891137217 - epoch_recon_loss: 630.8127488452 - epoch_kl_loss: 4.6935357677 - val_loss: 677.0313022893 - val_recon_loss: 674.8144319116 - val_kl_loss: 4.5708626829\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████-----------| 49.5%  - epoch_loss: 634.9958579042 - epoch_recon_loss: 632.7043752922 - epoch_kl_loss: 4.6764958580 - val_loss: 678.2612833163 - val_recon_loss: 676.0129547119 - val_kl_loss: 4.5884222519\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 50.0%  - epoch_loss: 634.1977792034 - epoch_recon_loss: 631.8875646585 - epoch_kl_loss: 4.6671013938 - val_loss: 677.2936762368 - val_recon_loss: 675.0347524503 - val_kl_loss: 4.5634803161\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 50.5%  - epoch_loss: 632.1852861034 - epoch_recon_loss: 629.8535084444 - epoch_kl_loss: 4.6635565400 - val_loss: 676.9474044428 - val_recon_loss: 674.6599958466 - val_kl_loss: 4.5748190444\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 51.0%  - epoch_loss: 631.2098016023 - epoch_recon_loss: 628.8854496809 - epoch_kl_loss: 4.6487030632 - val_loss: 677.7065102182 - val_recon_loss: 675.4027724848 - val_kl_loss: 4.6074757692\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 51.5%  - epoch_loss: 631.3585022262 - epoch_recon_loss: 629.0335337218 - epoch_kl_loss: 4.6499365306 - val_loss: 676.2963375929 - val_recon_loss: 674.0244590945 - val_kl_loss: 4.5437579271\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 52.0%  - epoch_loss: 633.5244240493 - epoch_recon_loss: 631.1981304342 - epoch_kl_loss: 4.6525881640 - val_loss: 677.1319081376 - val_recon_loss: 674.8846383444 - val_kl_loss: 4.4945409734\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 52.5%  - epoch_loss: 631.4898056845 - epoch_recon_loss: 629.1751431252 - epoch_kl_loss: 4.6293246419 - val_loss: 674.7024348189 - val_recon_loss: 672.4279344140 - val_kl_loss: 4.5489994055\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 53.0%  - epoch_loss: 630.7839613393 - epoch_recon_loss: 628.4647821784 - epoch_kl_loss: 4.6383579917 - val_loss: 676.0490838028 - val_recon_loss: 673.7960406048 - val_kl_loss: 4.5060860064\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 53.5%  - epoch_loss: 630.5463518474 - epoch_recon_loss: 628.2250424399 - epoch_kl_loss: 4.6426195186 - val_loss: 675.8390636909 - val_recon_loss: 673.5692719250 - val_kl_loss: 4.5395872157\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 54.0%  - epoch_loss: 628.9331738083 - epoch_recon_loss: 626.6149901931 - epoch_kl_loss: 4.6363666246 - val_loss: 674.2171258694 - val_recon_loss: 671.9649914997 - val_kl_loss: 4.5042682508\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████----------| 54.5%  - epoch_loss: 629.6720886437 - epoch_recon_loss: 627.3525999739 - epoch_kl_loss: 4.6389766015 - val_loss: 673.5916807593 - val_recon_loss: 671.3269210443 - val_kl_loss: 4.5295216543\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 55.0%  - epoch_loss: 628.0909497285 - epoch_recon_loss: 625.7736827549 - epoch_kl_loss: 4.6345342494 - val_loss: 672.9389209282 - val_recon_loss: 670.7052035448 - val_kl_loss: 4.4674317284\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 55.5%  - epoch_loss: 628.7419516129 - epoch_recon_loss: 626.4243973325 - epoch_kl_loss: 4.6351088817 - val_loss: 673.4644700958 - val_recon_loss: 671.2421588432 - val_kl_loss: 4.4446226591\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 56.0%  - epoch_loss: 628.2328934015 - epoch_recon_loss: 625.9164795995 - epoch_kl_loss: 4.6328275737 - val_loss: 672.1876514714 - val_recon_loss: 669.8997560827 - val_kl_loss: 4.5757919928\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 56.5%  - epoch_loss: 627.6428827643 - epoch_recon_loss: 625.3249225320 - epoch_kl_loss: 4.6359204080 - val_loss: 672.3924914104 - val_recon_loss: 670.1111762814 - val_kl_loss: 4.5626308744\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 57.0%  - epoch_loss: 627.7173543624 - epoch_recon_loss: 625.3902600271 - epoch_kl_loss: 4.6541884595 - val_loss: 672.8241930706 - val_recon_loss: 670.5300981475 - val_kl_loss: 4.5881883313\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 57.5%  - epoch_loss: 626.4865112305 - epoch_recon_loss: 624.1671355520 - epoch_kl_loss: 4.6387517905 - val_loss: 672.5025731529 - val_recon_loss: 670.2404081763 - val_kl_loss: 4.5243284673\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 58.0%  - epoch_loss: 628.1675532652 - epoch_recon_loss: 625.8462164146 - epoch_kl_loss: 4.6426742037 - val_loss: 672.3544322688 - val_recon_loss: 670.0558810350 - val_kl_loss: 4.5970985948\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 58.5%  - epoch_loss: 625.0512994917 - epoch_recon_loss: 622.7281457825 - epoch_kl_loss: 4.6463058051 - val_loss: 671.3858315072 - val_recon_loss: 669.1333677711 - val_kl_loss: 4.5049269665\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 59.0%  - epoch_loss: 625.0878728386 - epoch_recon_loss: 622.7639717891 - epoch_kl_loss: 4.6478016285 - val_loss: 670.7049136278 - val_recon_loss: 668.4966724675 - val_kl_loss: 4.4164833921\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████---------| 59.5%  - epoch_loss: 624.4241979675 - epoch_recon_loss: 622.0991227445 - epoch_kl_loss: 4.6501503429 - val_loss: 669.1155332240 - val_recon_loss: 666.8060183641 - val_kl_loss: 4.6190271537\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 60.0%  - epoch_loss: 625.0891665858 - epoch_recon_loss: 622.7598139497 - epoch_kl_loss: 4.6587054239 - val_loss: 668.0113958964 - val_recon_loss: 665.7192092523 - val_kl_loss: 4.5843724274\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 60.5%  - epoch_loss: 624.1592999008 - epoch_recon_loss: 621.8325558057 - epoch_kl_loss: 4.6534882943 - val_loss: 668.2310649593 - val_recon_loss: 665.9811181789 - val_kl_loss: 4.4998908348\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 61.0%  - epoch_loss: 623.4033930677 - epoch_recon_loss: 621.0770039381 - epoch_kl_loss: 4.6527783608 - val_loss: 669.8370912133 - val_recon_loss: 667.5741800448 - val_kl_loss: 4.5258221655\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 61.5%  - epoch_loss: 623.0602114911 - epoch_recon_loss: 620.7320278908 - epoch_kl_loss: 4.6563689394 - val_loss: 668.8278793707 - val_recon_loss: 666.5212841499 - val_kl_loss: 4.6131901479\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 62.0%  - epoch_loss: 622.4663848980 - epoch_recon_loss: 620.1373247684 - epoch_kl_loss: 4.6581198055 - val_loss: 668.2342678163 - val_recon_loss: 665.9542731308 - val_kl_loss: 4.5599883998\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 62.5%  - epoch_loss: 622.7027454183 - epoch_recon_loss: 620.3658606972 - epoch_kl_loss: 4.6737688940 - val_loss: 668.1292739496 - val_recon_loss: 665.8488226169 - val_kl_loss: 4.5608990047\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 63.0%  - epoch_loss: 620.7543560283 - epoch_recon_loss: 618.4225092457 - epoch_kl_loss: 4.6636940803 - val_loss: 667.1224640637 - val_recon_loss: 664.8203504609 - val_kl_loss: 4.6042239026\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 63.5%  - epoch_loss: 622.9396262849 - epoch_recon_loss: 620.6031679846 - epoch_kl_loss: 4.6729181924 - val_loss: 665.8708302568 - val_recon_loss: 663.5953812018 - val_kl_loss: 4.5509012298\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 64.0%  - epoch_loss: 620.5019272088 - epoch_recon_loss: 618.1613737342 - epoch_kl_loss: 4.6811062901 - val_loss: 665.7086959467 - val_recon_loss: 663.4449362406 - val_kl_loss: 4.5275216931\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████--------| 64.5%  - epoch_loss: 621.0042746481 - epoch_recon_loss: 618.6594268819 - epoch_kl_loss: 4.6896952580 - val_loss: 665.8144363775 - val_recon_loss: 663.5373122052 - val_kl_loss: 4.5542467484\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 65.0%  - epoch_loss: 620.5646901676 - epoch_recon_loss: 618.2261106995 - epoch_kl_loss: 4.6771583917 - val_loss: 665.3864042701 - val_recon_loss: 663.0800435136 - val_kl_loss: 4.6127236936\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 65.5%  - epoch_loss: 619.4801255665 - epoch_recon_loss: 617.1359581009 - epoch_kl_loss: 4.6883362047 - val_loss: 664.8650687613 - val_recon_loss: 662.5228498505 - val_kl_loss: 4.6844425667\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 66.0%  - epoch_loss: 618.7439902862 - epoch_recon_loss: 616.3958899528 - epoch_kl_loss: 4.6962015721 - val_loss: 664.6405070235 - val_recon_loss: 662.3353349639 - val_kl_loss: 4.6103444710\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 66.5%  - epoch_loss: 618.8064833532 - epoch_recon_loss: 616.4597692483 - epoch_kl_loss: 4.6934275053 - val_loss: 663.7096754865 - val_recon_loss: 661.3626924840 - val_kl_loss: 4.6939676041\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 67.0%  - epoch_loss: 618.4500516591 - epoch_recon_loss: 616.0979017525 - epoch_kl_loss: 4.7042996121 - val_loss: 664.2746328959 - val_recon_loss: 661.9785922911 - val_kl_loss: 4.5920837711\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 67.5%  - epoch_loss: 619.9102287989 - epoch_recon_loss: 617.5650612481 - epoch_kl_loss: 4.6903350851 - val_loss: 664.0234255907 - val_recon_loss: 661.7293809100 - val_kl_loss: 4.5880870441\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 68.0%  - epoch_loss: 618.1201282060 - epoch_recon_loss: 615.7755487428 - epoch_kl_loss: 4.6891575514 - val_loss: 663.2305885873 - val_recon_loss: 660.9463530750 - val_kl_loss: 4.5684736545\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 68.5%  - epoch_loss: 617.0151624699 - epoch_recon_loss: 614.6621305867 - epoch_kl_loss: 4.7060640526 - val_loss: 662.4008290361 - val_recon_loss: 660.0933782066 - val_kl_loss: 4.6148996571\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 69.0%  - epoch_loss: 618.3788922189 - epoch_recon_loss: 616.0276275490 - epoch_kl_loss: 4.7025288871 - val_loss: 661.7408934803 - val_recon_loss: 659.4431051859 - val_kl_loss: 4.5955777372\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████-------| 69.5%  - epoch_loss: 616.8389830264 - epoch_recon_loss: 614.4829398691 - epoch_kl_loss: 4.7120862439 - val_loss: 662.3019111447 - val_recon_loss: 659.9810798459 - val_kl_loss: 4.6416641168\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 70.0%  - epoch_loss: 616.6077159085 - epoch_recon_loss: 614.2504298047 - epoch_kl_loss: 4.7145725699 - val_loss: 661.8093648771 - val_recon_loss: 659.4667384450 - val_kl_loss: 4.6852486948\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 70.5%  - epoch_loss: 617.1239349180 - epoch_recon_loss: 614.7695777176 - epoch_kl_loss: 4.7087141236 - val_loss: 661.1760190638 - val_recon_loss: 658.8493849592 - val_kl_loss: 4.6532730475\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 71.0%  - epoch_loss: 615.0570733185 - epoch_recon_loss: 612.6977900569 - epoch_kl_loss: 4.7185662489 - val_loss: 660.2536483392 - val_recon_loss: 657.9056958454 - val_kl_loss: 4.6959032722\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 71.5%  - epoch_loss: 615.3182663985 - epoch_recon_loss: 612.9511450922 - epoch_kl_loss: 4.7342425334 - val_loss: 659.7278085104 - val_recon_loss: 657.3940671595 - val_kl_loss: 4.6674793842\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 72.0%  - epoch_loss: 615.2483449940 - epoch_recon_loss: 612.8862754920 - epoch_kl_loss: 4.7241389706 - val_loss: 659.2618858523 - val_recon_loss: 656.9284306968 - val_kl_loss: 4.6669078629\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 72.5%  - epoch_loss: 614.0955361965 - epoch_recon_loss: 611.7339314118 - epoch_kl_loss: 4.7232073198 - val_loss: 659.7409954536 - val_recon_loss: 657.4105485125 - val_kl_loss: 4.6608935624\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 73.0%  - epoch_loss: 612.5260573072 - epoch_recon_loss: 610.1674387469 - epoch_kl_loss: 4.7172369617 - val_loss: 658.4241143203 - val_recon_loss: 656.1139801770 - val_kl_loss: 4.6202673854\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 73.5%  - epoch_loss: 615.3160938523 - epoch_recon_loss: 612.9580496994 - epoch_kl_loss: 4.7160886064 - val_loss: 659.9931153088 - val_recon_loss: 657.6678749643 - val_kl_loss: 4.6504781450\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 74.0%  - epoch_loss: 612.4877525263 - epoch_recon_loss: 610.1222004713 - epoch_kl_loss: 4.7311047328 - val_loss: 658.3332404160 - val_recon_loss: 656.0077153648 - val_kl_loss: 4.6510526654\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████------| 74.5%  - epoch_loss: 613.5646181139 - epoch_recon_loss: 611.2002174321 - epoch_kl_loss: 4.7288007349 - val_loss: 657.4219594816 - val_recon_loss: 655.0776713301 - val_kl_loss: 4.6885742560\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 75.0%  - epoch_loss: 612.0124888494 - epoch_recon_loss: 609.6464764928 - epoch_kl_loss: 4.7320258716 - val_loss: 657.4828941531 - val_recon_loss: 655.1398832740 - val_kl_loss: 4.6860207174\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 75.5%  - epoch_loss: 612.3810050505 - epoch_recon_loss: 610.0128232016 - epoch_kl_loss: 4.7363626726 - val_loss: 657.0580716017 - val_recon_loss: 654.7134470126 - val_kl_loss: 4.6892497162\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 76.0%  - epoch_loss: 611.3323507870 - epoch_recon_loss: 608.9621133243 - epoch_kl_loss: 4.7404745085 - val_loss: 656.6381445164 - val_recon_loss: 654.3221044773 - val_kl_loss: 4.6320828025\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 76.5%  - epoch_loss: 611.9543662132 - epoch_recon_loss: 609.5895974634 - epoch_kl_loss: 4.7295366447 - val_loss: 655.7874009667 - val_recon_loss: 653.3849282614 - val_kl_loss: 4.8049429015\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 77.0%  - epoch_loss: 611.7132087589 - epoch_recon_loss: 609.3374771624 - epoch_kl_loss: 4.7514632319 - val_loss: 656.3423134408 - val_recon_loss: 653.9987022586 - val_kl_loss: 4.6872229053\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 77.5%  - epoch_loss: 612.2356880606 - epoch_recon_loss: 609.8653333147 - epoch_kl_loss: 4.7407075051 - val_loss: 655.5459069973 - val_recon_loss: 653.2023021419 - val_kl_loss: 4.6872105686\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 78.0%  - epoch_loss: 611.2026596224 - epoch_recon_loss: 608.8335647635 - epoch_kl_loss: 4.7381908726 - val_loss: 657.0597485798 - val_recon_loss: 654.7313969310 - val_kl_loss: 4.6566998115\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 78.5%  - epoch_loss: 609.1074614921 - epoch_recon_loss: 606.7362092323 - epoch_kl_loss: 4.7425055975 - val_loss: 655.1916083359 - val_recon_loss: 652.9203885706 - val_kl_loss: 4.5424414321\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 79.0%  - epoch_loss: 609.4104826375 - epoch_recon_loss: 607.0425556175 - epoch_kl_loss: 4.7358537779 - val_loss: 656.2118206489 - val_recon_loss: 653.8927679294 - val_kl_loss: 4.6381077795\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████-----| 79.5%  - epoch_loss: 609.3786827433 - epoch_recon_loss: 607.0061056409 - epoch_kl_loss: 4.7451556301 - val_loss: 655.6384936077 - val_recon_loss: 653.2844718375 - val_kl_loss: 4.7080417028\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 80.0%  - epoch_loss: 609.2135096428 - epoch_recon_loss: 606.8415532709 - epoch_kl_loss: 4.7439120449 - val_loss: 653.5498368798 - val_recon_loss: 651.1575362043 - val_kl_loss: 4.7845982022\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 80.5%  - epoch_loss: 609.8365389996 - epoch_recon_loss: 607.4663425572 - epoch_kl_loss: 4.7403933857 - val_loss: 653.0304219316 - val_recon_loss: 650.6934808871 - val_kl_loss: 4.6738838917\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 81.0%  - epoch_loss: 609.3725925985 - epoch_recon_loss: 606.9998582449 - epoch_kl_loss: 4.7454684169 - val_loss: 653.9850813703 - val_recon_loss: 651.6211748821 - val_kl_loss: 4.7278139402\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 81.5%  - epoch_loss: 607.5815632932 - epoch_recon_loss: 605.2094621948 - epoch_kl_loss: 4.7442012623 - val_loss: 653.3975547232 - val_recon_loss: 651.0128036127 - val_kl_loss: 4.7695028433\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 82.0%  - epoch_loss: 607.8201656690 - epoch_recon_loss: 605.4433623669 - epoch_kl_loss: 4.7536067028 - val_loss: 654.0247505002 - val_recon_loss: 651.6896485119 - val_kl_loss: 4.6702068550\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 82.5%  - epoch_loss: 606.7949706742 - epoch_recon_loss: 604.4219971116 - epoch_kl_loss: 4.7459468471 - val_loss: 652.3377808362 - val_recon_loss: 650.0002579108 - val_kl_loss: 4.6750441339\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 83.0%  - epoch_loss: 607.4058486908 - epoch_recon_loss: 605.0259799919 - epoch_kl_loss: 4.7597369272 - val_loss: 653.7217704959 - val_recon_loss: 651.3342486126 - val_kl_loss: 4.7750450198\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 83.5%  - epoch_loss: 606.6997100025 - epoch_recon_loss: 604.3253796147 - epoch_kl_loss: 4.7486610171 - val_loss: 651.9174235274 - val_recon_loss: 649.5267553562 - val_kl_loss: 4.7813335192\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 84.0%  - epoch_loss: 606.3261146984 - epoch_recon_loss: 603.9539589408 - epoch_kl_loss: 4.7443105799 - val_loss: 652.3136079370 - val_recon_loss: 649.9319912050 - val_kl_loss: 4.7632355457\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████----| 84.5%  - epoch_loss: 606.4289245399 - epoch_recon_loss: 604.0542634728 - epoch_kl_loss: 4.7493233239 - val_loss: 652.2019541671 - val_recon_loss: 649.8392330263 - val_kl_loss: 4.7254383593\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 85.0%  - epoch_loss: 605.9964005352 - epoch_recon_loss: 603.6178391607 - epoch_kl_loss: 4.7571224040 - val_loss: 651.4633055896 - val_recon_loss: 649.1148335527 - val_kl_loss: 4.6969394175\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 85.5%  - epoch_loss: 605.7174381981 - epoch_recon_loss: 603.3396585399 - epoch_kl_loss: 4.7555600596 - val_loss: 650.2776070572 - val_recon_loss: 647.9221917129 - val_kl_loss: 4.7108322411\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 86.0%  - epoch_loss: 606.7747949235 - epoch_recon_loss: 604.3949391415 - epoch_kl_loss: 4.7597122176 - val_loss: 651.8486953363 - val_recon_loss: 649.4461160055 - val_kl_loss: 4.8051551580\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 86.5%  - epoch_loss: 605.5476576449 - epoch_recon_loss: 603.1671601064 - epoch_kl_loss: 4.7609945565 - val_loss: 650.5098489901 - val_recon_loss: 648.1296825874 - val_kl_loss: 4.7603337648\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 87.0%  - epoch_loss: 605.0555153332 - epoch_recon_loss: 602.6764910777 - epoch_kl_loss: 4.7580467721 - val_loss: 650.4060639172 - val_recon_loss: 648.0756616360 - val_kl_loss: 4.6608059464\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 87.5%  - epoch_loss: 604.1187738157 - epoch_recon_loss: 601.7454566156 - epoch_kl_loss: 4.7466344326 - val_loss: 650.0469550156 - val_recon_loss: 647.6817120808 - val_kl_loss: 4.7304826626\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 88.0%  - epoch_loss: 604.3531165236 - epoch_recon_loss: 601.9754240024 - epoch_kl_loss: 4.7553863754 - val_loss: 649.6357574463 - val_recon_loss: 647.2667117235 - val_kl_loss: 4.7380940623\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 88.5%  - epoch_loss: 603.9340235753 - epoch_recon_loss: 601.5498998924 - epoch_kl_loss: 4.7682470605 - val_loss: 649.4423496898 - val_recon_loss: 647.0698037496 - val_kl_loss: 4.7450930462\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 89.0%  - epoch_loss: 602.9966772156 - epoch_recon_loss: 600.6249965335 - epoch_kl_loss: 4.7433623686 - val_loss: 649.9715672935 - val_recon_loss: 647.5981244343 - val_kl_loss: 4.7468836511\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |█████████████████---| 89.5%  - epoch_loss: 602.6677154066 - epoch_recon_loss: 600.2977281716 - epoch_kl_loss: 4.7399741913 - val_loss: 648.7722886248 - val_recon_loss: 646.4596040307 - val_kl_loss: 4.6253665439\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 90.0%  - epoch_loss: 603.6585603808 - epoch_recon_loss: 601.2855823612 - epoch_kl_loss: 4.7459564815 - val_loss: 648.0476725509 - val_recon_loss: 645.6941215701 - val_kl_loss: 4.7071003769\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 90.5%  - epoch_loss: 603.6533126573 - epoch_recon_loss: 601.2722666897 - epoch_kl_loss: 4.7620916439 - val_loss: 650.5885188405 - val_recon_loss: 648.1971115484 - val_kl_loss: 4.7828141945\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 91.0%  - epoch_loss: 602.9041271403 - epoch_recon_loss: 600.5276653504 - epoch_kl_loss: 4.7529243572 - val_loss: 648.5709429485 - val_recon_loss: 646.1812532006 - val_kl_loss: 4.7793858836\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 91.5%  - epoch_loss: 602.0433193617 - epoch_recon_loss: 599.6630215803 - epoch_kl_loss: 4.7605977687 - val_loss: 648.0166581317 - val_recon_loss: 645.6612533942 - val_kl_loss: 4.7108081783\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 92.0%  - epoch_loss: 603.5515288172 - epoch_recon_loss: 601.1762880812 - epoch_kl_loss: 4.7504808887 - val_loss: 647.6677327970 - val_recon_loss: 645.2847237936 - val_kl_loss: 4.7660193531\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 92.5%  - epoch_loss: 602.2219857712 - epoch_recon_loss: 599.8486781246 - epoch_kl_loss: 4.7466162608 - val_loss: 647.5009479057 - val_recon_loss: 645.1772062720 - val_kl_loss: 4.6474838141\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 93.0%  - epoch_loss: 601.2731267943 - epoch_recon_loss: 598.8948072081 - epoch_kl_loss: 4.7566384805 - val_loss: 646.8092856058 - val_recon_loss: 644.4395926871 - val_kl_loss: 4.7393825461\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 93.5%  - epoch_loss: 600.8497041054 - epoch_recon_loss: 598.4743024866 - epoch_kl_loss: 4.7508030421 - val_loss: 647.8264376012 - val_recon_loss: 645.4307537544 - val_kl_loss: 4.7913691794\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 94.0%  - epoch_loss: 600.9421367323 - epoch_recon_loss: 598.5646016893 - epoch_kl_loss: 4.7550693110 - val_loss: 646.2372216946 - val_recon_loss: 643.8539897640 - val_kl_loss: 4.7664650795\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |██████████████████--| 94.5%  - epoch_loss: 601.7324642571 - epoch_recon_loss: 599.3579360725 - epoch_kl_loss: 4.7490563151 - val_loss: 646.6552619004 - val_recon_loss: 644.3105089141 - val_kl_loss: 4.6895077926\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 95.0%  - epoch_loss: 600.0188900714 - epoch_recon_loss: 597.6445818444 - epoch_kl_loss: 4.7486167177 - val_loss: 645.0532092583 - val_recon_loss: 642.6855159853 - val_kl_loss: 4.7353871741\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 95.5%  - epoch_loss: 599.2373304799 - epoch_recon_loss: 596.8682650656 - epoch_kl_loss: 4.7381307574 - val_loss: 645.7321073951 - val_recon_loss: 643.3628260915 - val_kl_loss: 4.7385579638\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 96.0%  - epoch_loss: 601.1791365329 - epoch_recon_loss: 598.8034873483 - epoch_kl_loss: 4.7512982462 - val_loss: 645.0373470027 - val_recon_loss: 642.6660677282 - val_kl_loss: 4.7425520144\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 96.5%  - epoch_loss: 600.6446456032 - epoch_recon_loss: 598.2754529395 - epoch_kl_loss: 4.7383869507 - val_loss: 647.0302674829 - val_recon_loss: 644.6869391465 - val_kl_loss: 4.6866574578\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 97.0%  - epoch_loss: 599.4106567465 - epoch_recon_loss: 597.0341472510 - epoch_kl_loss: 4.7530186252 - val_loss: 644.9345922703 - val_recon_loss: 642.5445485929 - val_kl_loss: 4.7800853819\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 97.5%  - epoch_loss: 600.0077052448 - epoch_recon_loss: 597.6349867794 - epoch_kl_loss: 4.7454365646 - val_loss: 645.7994987674 - val_recon_loss: 643.4331177502 - val_kl_loss: 4.7327632090\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 98.0%  - epoch_loss: 599.9989575946 - epoch_recon_loss: 597.6221014697 - epoch_kl_loss: 4.7537106468 - val_loss: 644.8122811666 - val_recon_loss: 642.4879530000 - val_kl_loss: 4.6486535727\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 98.5%  - epoch_loss: 598.9133476170 - epoch_recon_loss: 596.5386045919 - epoch_kl_loss: 4.7494865536 - val_loss: 644.6279642989 - val_recon_loss: 642.3020235387 - val_kl_loss: 4.6518796653\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 99.0%  - epoch_loss: 599.2498066601 - epoch_recon_loss: 596.8833951608 - epoch_kl_loss: 4.7328208850 - val_loss: 644.3556403183 - val_recon_loss: 641.9927185803 - val_kl_loss: 4.7258406122\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |███████████████████-| 99.5%  - epoch_loss: 598.7257103601 - epoch_recon_loss: 596.3556255885 - epoch_kl_loss: 4.7401691200 - val_loss: 645.1063321742 - val_recon_loss: 642.7785581263 - val_kl_loss: 4.6555461665\n",
            "Number of deactivated terms: 0\n",
            "-------------------\n",
            " |████████████████████| 100.0%  - epoch_loss: 598.8627309432 - epoch_recon_loss: 596.4945717296 - epoch_kl_loss: 4.7363188534 - val_loss: 644.4149839820 - val_recon_loss: 642.0587228915 - val_kl_loss: 4.7125206837\n",
            "Saving best state of network...\n",
            "Best State was in Epoch 197\n"
          ]
        }
      ],
      "source": [
        "early_stopping_kwargs = {\n",
        "    \"early_stopping_metric\": \"val_unweighted_loss\", # val_unweighted_loss\n",
        "    \"threshold\": 0,\n",
        "    \"patience\": 50,\n",
        "    \"reduce_lr\": True,\n",
        "    \"lr_patience\": 13,\n",
        "    \"lr_factor\": 0.1,\n",
        "}\n",
        "intr_cvae.train(\n",
        "    n_epochs=200,\n",
        "    alpha_epoch_anneal=100,\n",
        "    alpha=ALPHA,\n",
        "    alpha_kl=0.5,\n",
        "    weight_decay=0.,\n",
        "    early_stopping_kwargs=early_stopping_kwargs,\n",
        "    use_early_stopping=True,\n",
        "    monitor_only_val=False,\n",
        "    seed=2020,\n",
        "    print_stats=True,\n",
        "    use_gpu = True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I0GlpuqVUeh"
      },
      "outputs": [],
      "source": [
        "MEAN = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQn4ajy2VWze"
      },
      "outputs": [],
      "source": [
        "adata_healthy.obsm['expimap_X_cvae'] = intr_cvae.get_latent(mean=MEAN, only_active=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNMuR4CNViad"
      },
      "source": [
        "### Initlizling the model for query training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_mO5jiU-mwe"
      },
      "outputs": [],
      "source": [
        "#adata_cancer.X = adata_cancer.X.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cojXuRr-VxGz",
        "outputId": "87e6a4d3-efab-4618-91b4-eaf1b18a156c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View of AnnData object with n_obs × n_vars = 113593 × 4655\n",
            "    obs: 'Sample_ID', 'Donor_ID', 'SpecimenType', 'TissueSource', 'ProcessingMethod', 'PatientTypeID', 'Gender', 'Site', 'Grade', 'TumorStage', 'LymphNodeStatus', 'MMRStatusTumor', 'MMRMLH1Tumor', 'Diagnosis', 'organ__ontology_label', 'Library_Preparation_Protocol', 'ClusterFull', 'ClusterMidway', 'Cell Type', 'Study_name', 'n_genes_by_counts', 'total_counts', 'total_counts_mito', 'pct_counts_mito', 'total_counts_ribo', 'pct_counts_ribo'\n",
            "    var: 'gene_id', 'gene_name', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'mito', 'ribo'\n",
            "    uns: 'log1p'\n",
            "\n",
            "INITIALIZING NEW NETWORK..............\n",
            "Encoder Architecture:\n",
            "\tInput Layer in, out and cond: 4655 256 425\n",
            "\tHidden Layer 1 in/out: 256 256\n",
            "\tHidden Layer 2 in/out: 256 256\n",
            "\tMean/Var Layer in/out: 256 1\n",
            "Decoder Architecture:\n",
            "\tMasked linear layer in, ext_m, ext, cond, out:  1 0 0 425 4655\n",
            "\twith hard mask.\n",
            "Last Decoder layer: softmax\n"
          ]
        }
      ],
      "source": [
        "q_intr_cvae = sca.models.EXPIMAP.load_query_data(adata_cancer, intr_cvae)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q_intr_cvae.model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puOrXtYZjgPX",
        "outputId": "a5c05891-228c-4356-e493-7fae81addf35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "expiMap(\n",
              "  (encoder): ExtEncoder(\n",
              "    (FC): Sequential(\n",
              "      (L0): MaskedCondLayers(\n",
              "        (expr_L): Linear(in_features=4655, out_features=256, bias=True)\n",
              "        (cond_L): Linear(in_features=425, out_features=256, bias=False)\n",
              "      )\n",
              "      (N0): LayerNorm((256,), eps=1e-05, elementwise_affine=False)\n",
              "      (A0): ReLU()\n",
              "      (L1): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (N1): LayerNorm((256,), eps=1e-05, elementwise_affine=False)\n",
              "      (A1): ReLU()\n",
              "      (L2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (N2): LayerNorm((256,), eps=1e-05, elementwise_affine=False)\n",
              "      (A2): ReLU()\n",
              "    )\n",
              "    (mean_encoder): Linear(in_features=256, out_features=1, bias=True)\n",
              "    (log_var_encoder): Linear(in_features=256, out_features=1, bias=True)\n",
              "  )\n",
              "  (decoder): MaskedLinearDecoder(\n",
              "    (L0): MaskedCondLayers(\n",
              "      (expr_L): MaskedLinear(in_features=1, out_features=4655, bias=False)\n",
              "      (cond_L): Linear(in_features=425, out_features=4655, bias=False)\n",
              "    )\n",
              "    (mean_decoder): Softmax(dim=-1)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6y6Fr5uVzAr"
      },
      "outputs": [],
      "source": [
        "q_intr_cvae.train(n_epochs=200, alpha_epoch_anneal=100, weight_decay=0., alpha_kl=0.1, seed=2020, use_early_stopping=True, print_stats=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3biw6ScIcO43"
      },
      "outputs": [],
      "source": [
        "adata_cancer.obsm['expimap_X_cvae'] = q_intr_cvae.get_latent(mean=MEAN, only_active=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O8ti3IcfDAI"
      },
      "source": [
        "### Transfer labels from latent embedding to obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mWrzy6acaul"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Use the embeddings and labels from reference dataset to train the classifier\n",
        "X_train = adata_healthy.obsm['expimap_X_cvae']\n",
        "y_train = adata_healthy.obs['Cell States']\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Use the trained classifier to predict labels for query dataset\n",
        "X_query = adata_cancer.obsm['expimap_X_cvae']\n",
        "predicted_labels = knn.predict(X_query)\n",
        "\n",
        "# Store these predicted labels in obs dataframe of query adata\n",
        "adata_cancer.obs['Predicted Cell States'] = predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTxjFsK1fMrZ"
      },
      "outputs": [],
      "source": [
        "adata_cancer.obs['Predicted Cell States'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg3yKpSRpYvy"
      },
      "source": [
        "### Get latent representation of reference + query dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0n9FpHuaOVH"
      },
      "outputs": [],
      "source": [
        "adata = sc.AnnData.concatenate(adata_healthy, adata_cancer, batch_key='batch_join', uns_merge='same')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7MB6Gskav9M"
      },
      "outputs": [],
      "source": [
        "adata.obsm['expimap_X_cvae'] = q_intr_cvae.get_latent(adata.X, adata.obs['Predicted Cell States'], mean=MEAN, only_active=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IvS5CCz_-xo"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SOqqzXoBBWx"
      },
      "outputs": [],
      "source": [
        "q_intr_cvae.save('/content/gdrive/MyDrive/Colab Notebooks/gut_data/cancer_integration/output_files/cancer_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Zuxo_Mt7kVa"
      },
      "outputs": [],
      "source": [
        "adata.write('/content/gdrive/MyDrive/Colab Notebooks/gut_data/cancer_integration/output_files/Epithelial_healthy_and_cancer_integrated_andata.h5ad')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB1AHc-H3xGd"
      },
      "source": [
        "### Read data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZpVxBX53SYX"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "\n",
        "input_path = '/gdrive/MyDrive/Colab Notebooks/gut_data/cancer_integration/output_files/Epithelial_healthy_and_cancer_integrated_andata.h5ad'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eaaWTSq3ekD"
      },
      "outputs": [],
      "source": [
        "adata = sc.read_h5ad(input_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JKtbG8C4Gjv"
      },
      "source": [
        "### Run UMAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGXkNyum4IUA"
      },
      "outputs": [],
      "source": [
        "sc.pp.neighbors(adata, use_rep='X_cvae')\n",
        "sc.tl.umap(adata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qEjWddQeJ9c"
      },
      "outputs": [],
      "source": [
        "sc.pl.umap(adata, color=['seed_labels', 'Cell States', 'Study_name', 'Donor_ID', 'Diagnosis', 'Location', 'Gender', 'Library_Preparation_Protocol'], frameon=False, wspace=0.6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrNU8t6vUkSD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "adata.write('/content/gdrive/MyDrive/Colab Notebooks/gut_data/cancer_integration/output_files/Epithelial_healthy_and_cancer_integrated_andata_with_umap.h5ad')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6OigWivUu1R"
      },
      "source": [
        "### scIB metrics calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wnD-0JEU2ig"
      },
      "outputs": [],
      "source": [
        "from rich import print\n",
        "import scib\n",
        "import scib.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZaaFM8pU5p9"
      },
      "outputs": [],
      "source": [
        "from scvi_colab import install\n",
        "from scib_metrics.benchmark import Benchmarker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwRVKMaDVBIF"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "\n",
        "from scib_metrics.nearest_neighbors import NeighborsOutput\n",
        "\n",
        "\n",
        "def faiss_hnsw_nn(X: np.ndarray, k: int):\n",
        "    \"\"\"Gpu HNSW nearest neighbor search using faiss.\n",
        "\n",
        "    See https://github.com/nmslib/hnswlib/blob/master/ALGO_PARAMS.md\n",
        "    for index param details.\n",
        "    \"\"\"\n",
        "    X = np.ascontiguousarray(X, dtype=np.float32)\n",
        "    res = faiss.StandardGpuResources()\n",
        "    M = 32\n",
        "    index = faiss.IndexHNSWFlat(X.shape[1], M, faiss.METRIC_L2)\n",
        "    gpu_index = faiss.index_cpu_to_gpu(res, 0, index)\n",
        "    gpu_index.add(X)\n",
        "    distances, indices = gpu_index.search(X, k)\n",
        "    del index\n",
        "    del gpu_index\n",
        "    # distances are squared\n",
        "    return NeighborsOutput(indices=indices, distances=np.sqrt(distances))\n",
        "\n",
        "\n",
        "def faiss_brute_force_nn(X: np.ndarray, k: int):\n",
        "    \"\"\"Gpu brute force nearest neighbor search using faiss.\"\"\"\n",
        "    X = np.ascontiguousarray(X, dtype=np.float32)\n",
        "    res = faiss.StandardGpuResources()\n",
        "    index = faiss.IndexFlatL2(X.shape[1])\n",
        "    gpu_index = faiss.index_cpu_to_gpu(res, 0, index)\n",
        "    gpu_index.add(X)\n",
        "    distances, indices = gpu_index.search(X, k)\n",
        "    del index\n",
        "    del gpu_index\n",
        "    # distances are squared\n",
        "    return NeighborsOutput(indices=indices, distances=np.sqrt(distances))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRLFmtTSVDVu"
      },
      "outputs": [],
      "source": [
        "bm = Benchmarker(\n",
        "    adata,\n",
        "    batch_key=\"Sample_ID\",\n",
        "    label_key=\"Cell States\",\n",
        "    embedding_obsm_keys=[\"X_pca\", 'X_cvae'],\n",
        "    n_jobs=-1\n",
        ")\n",
        "bm.prepare(neighbor_computer=faiss_brute_force_nn)\n",
        "bm.benchmark()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SA0kf_L5VFFc"
      },
      "outputs": [],
      "source": [
        "bm.plot_results_table(min_max_scale=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}